{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [6000/6000], Loss: 0.0976\n",
      "Accuracy of the network on the 5000 validation images: 97.75 %\n",
      "Epoch [2/10], Step [6000/6000], Loss: 0.0016\n",
      "Accuracy of the network on the 5000 validation images: 98.0 %\n",
      "Epoch [3/10], Step [6000/6000], Loss: 0.0080\n",
      "Accuracy of the network on the 5000 validation images: 97.55 %\n",
      "Epoch [4/10], Step [6000/6000], Loss: 0.0281\n",
      "Accuracy of the network on the 5000 validation images: 97.56 %\n",
      "Epoch [5/10], Step [6000/6000], Loss: 0.0004\n",
      "Accuracy of the network on the 5000 validation images: 98.61 %\n",
      "Epoch [6/10], Step [6000/6000], Loss: 0.0869\n",
      "Accuracy of the network on the 5000 validation images: 98.19 %\n",
      "Epoch [7/10], Step [6000/6000], Loss: 0.0249\n",
      "Accuracy of the network on the 5000 validation images: 97.71 %\n",
      "Epoch [8/10], Step [6000/6000], Loss: 0.0294\n",
      "Accuracy of the network on the 5000 validation images: 98.69 %\n",
      "Epoch [9/10], Step [6000/6000], Loss: 0.2552\n",
      "Accuracy of the network on the 5000 validation images: 96.76 %\n",
      "Epoch [10/10], Step [6000/6000], Loss: 0.0213\n",
      "Accuracy of the network on the 5000 validation images: 98.59 %\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "_ = torch.manual_seed(0)\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor() ,\n",
    "\n",
    "transforms.Normalize((0.1307,),(0.3081,))\n",
    "\n",
    "])\n",
    "\n",
    "# mnist_trainset = datasets.MNIST(root='./',train=True , download=True , transform= transform)\n",
    "\n",
    "# train_loader = torch.utils.data.DataLoader(mnist_trainset , batch_size = 10 , shuffle = True)\n",
    "\n",
    "# mnist_testset = datasets.MNIST(root='../data' , train = False , download = True , transform = transform)\n",
    "\n",
    "# test_loader = torch.utils.data.DataLoader(mnist_testset,batch_size = 10 , shuffle = True)\n",
    "\n",
    "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=False, transform=transform)\n",
    "mnist_testset = datasets.MNIST(root='./data', train=False, download=False, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(mnist_trainset, batch_size=10, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_testset, batch_size=10, shuffle=False)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class SimplifiedVGG16(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(SimplifiedVGG16, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256 * 3 * 3, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "model = SimplifiedVGG16(num_classes=10).to(device)\n",
    "\n",
    "\n",
    "num_classes = 10\n",
    "num_epochs = 10\n",
    "batch_size = 10\n",
    "learning_rate = 0.005\n",
    "\n",
    "model =SimplifiedVGG16(num_classes).to(device)\n",
    "\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = 0.005, momentum = 0.9)  \n",
    "\n",
    "\n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "\n",
    "total_step = len(train_loader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        # Move tensors to the configured device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "            \n",
    "    # Validation\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            del images, labels, outputs\n",
    "    \n",
    "        print('Accuracy of the network on the {} validation images: {} %'.format(5000, 100 * correct / total)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'features.0.weight': tensor([[[[-8.6525e-02, -1.2600e-01, -9.7478e-02],\n",
      "          [-5.5020e-03, -1.7209e-02,  1.8196e-02],\n",
      "          [ 1.1806e-01,  1.2425e-01,  9.7756e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2128e-04,  4.4156e-04,  4.4229e-04],\n",
      "          [-2.3406e-04, -2.8685e-05,  2.5882e-04],\n",
      "          [-4.6019e-04, -4.5711e-04, -1.4409e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 7.8280e-02,  1.5992e-01,  1.4662e-01],\n",
      "          [-7.9666e-02,  3.6879e-03,  1.0965e-01],\n",
      "          [-1.7504e-01, -1.6032e-01, -2.7079e-02]]],\n",
      "\n",
      "\n",
      "        [[[-9.4315e-02, -1.5960e-01, -1.3258e-01],\n",
      "          [ 2.2310e-02, -2.3756e-02,  5.7980e-03],\n",
      "          [ 1.4856e-01,  1.5313e-01,  1.3063e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 9.1576e-02,  7.3934e-02, -3.1834e-02],\n",
      "          [ 1.0505e-01,  1.4392e-02, -9.6077e-02],\n",
      "          [ 9.0354e-02, -2.6740e-02, -8.9094e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.8751e-02, -3.3857e-02,  3.2887e-02],\n",
      "          [-4.4856e-02,  1.9397e-02,  6.2933e-02],\n",
      "          [ 1.4961e-02,  6.7367e-02,  5.3186e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.3094e-01,  2.4084e-01,  2.4140e-01],\n",
      "          [ 1.6300e-02, -1.5163e-02, -3.7698e-02],\n",
      "          [-2.3040e-01, -2.4832e-01, -2.0616e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6667e-01,  8.2649e-02, -9.8212e-02],\n",
      "          [ 1.6076e-01,  4.0699e-03, -1.6318e-01],\n",
      "          [ 1.7852e-01,  9.7000e-03, -1.1908e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5112e-01,  1.5769e-01,  1.6706e-01],\n",
      "          [-1.2357e-02,  3.0178e-03,  6.5317e-02],\n",
      "          [-1.7292e-01, -1.6853e-01, -1.0297e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.1423e-04, -4.6617e-04, -4.4380e-04],\n",
      "          [-4.4281e-04, -3.7485e-04,  1.9218e-04],\n",
      "          [-4.5562e-04,  2.3657e-04,  7.2223e-04]]],\n",
      "\n",
      "\n",
      "        [[[-6.3486e-02, -1.1827e-01, -9.9262e-02],\n",
      "          [ 1.9513e-02, -1.7771e-02,  2.7528e-03],\n",
      "          [ 1.0735e-01,  1.1235e-01,  9.8868e-02]]],\n",
      "\n",
      "\n",
      "        [[[-8.6187e-02,  4.2559e-02,  1.0023e-01],\n",
      "          [ 4.3992e-03,  1.3705e-01,  1.1273e-01],\n",
      "          [ 1.1838e-01,  1.5559e-01,  5.8597e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.2659e-01, -9.3755e-02,  3.2886e-02],\n",
      "          [-1.0343e-01,  1.7837e-02,  1.2902e-01],\n",
      "          [ 2.4988e-02,  1.3896e-01,  1.2381e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.8325e-02,  7.0709e-02,  3.6967e-02],\n",
      "          [ 5.0591e-02,  1.0906e-01,  3.9294e-02],\n",
      "          [ 5.2121e-02,  7.5932e-02,  2.0639e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.3778e-02,  2.5273e-02,  2.5920e-02],\n",
      "          [-2.6263e-03, -1.3444e-03,  4.6898e-03],\n",
      "          [-2.5156e-02, -2.5922e-02, -1.8301e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5166e-03, -2.3162e-02, -2.1747e-02],\n",
      "          [ 2.0588e-02, -3.9825e-03, -1.2816e-02],\n",
      "          [ 2.2867e-02,  2.0455e-02,  1.0606e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.4741e-02, -1.0288e-01, -8.8361e-02],\n",
      "          [ 3.2428e-02, -1.3985e-02, -5.8765e-03],\n",
      "          [ 8.5715e-02,  9.2323e-02,  8.4886e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7328e-01,  4.8057e-03, -1.8456e-01],\n",
      "          [ 1.6031e-01,  3.7923e-02, -1.4152e-01],\n",
      "          [ 1.4549e-01,  1.6043e-01,  1.8575e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.7660e-03,  1.1972e-02,  1.2346e-02],\n",
      "          [-5.7028e-03, -7.3295e-04,  6.5365e-03],\n",
      "          [-1.2526e-02, -1.2761e-02, -4.9253e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 6.9180e-02,  1.4111e-01,  7.8265e-02],\n",
      "          [ 1.5729e-01,  1.0870e-01, -6.5005e-02],\n",
      "          [ 1.0633e-01, -3.8243e-02, -1.4647e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 7.2301e-02,  5.5197e-02, -4.6204e-02],\n",
      "          [ 3.2139e-02,  9.8484e-02,  4.5654e-02],\n",
      "          [-2.5331e-02,  5.7160e-02,  6.6935e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.2965e-02,  9.2506e-02,  1.0265e-01],\n",
      "          [ 6.7623e-02,  1.8522e-01,  8.6073e-02],\n",
      "          [ 1.4740e-01,  1.5901e-01,  1.3391e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.2647e-02, -8.6916e-02, -5.3833e-02],\n",
      "          [-1.3988e-02, -7.1775e-03,  3.1485e-02],\n",
      "          [ 7.7719e-02,  8.4456e-02,  7.0240e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2692e-03,  2.7587e-03,  1.4159e-03],\n",
      "          [ 2.4722e-03,  4.8508e-04, -1.5502e-03],\n",
      "          [-4.4763e-04, -2.6658e-03, -2.6497e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 7.2692e-02, -1.9448e-01, -2.7274e-01],\n",
      "          [ 2.3941e-01,  7.3189e-02, -9.1429e-02],\n",
      "          [ 1.7003e-01,  2.4050e-01,  1.5862e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8428e-01,  1.8929e-01,  1.9133e-01],\n",
      "          [ 1.1493e-02, -1.0688e-02, -2.6475e-02],\n",
      "          [-1.8395e-01, -1.9383e-01, -1.6519e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 9.8692e-02, -2.8677e-02, -1.1861e-01],\n",
      "          [ 1.1202e-01,  1.5063e-02, -9.4463e-02],\n",
      "          [ 9.9713e-02,  1.0087e-01,  1.3159e-02]]],\n",
      "\n",
      "\n",
      "        [[[-9.3873e-02, -6.6986e-02,  2.9630e-02],\n",
      "          [-5.8115e-02,  3.6273e-02,  9.2773e-02],\n",
      "          [ 5.0285e-02,  1.0856e-01,  7.2773e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.2461e-02,  1.2509e-01,  8.3758e-03],\n",
      "          [-2.0682e-02,  1.0352e-01,  1.0108e-01],\n",
      "          [-1.1412e-01, -7.8157e-03,  7.9124e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.2434e-02, -6.6347e-02, -9.1491e-02],\n",
      "          [ 9.0143e-02,  2.4047e-04, -6.3661e-02],\n",
      "          [ 8.4961e-02,  8.2204e-02,  2.4948e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.1856e-02, -4.4129e-02, -1.0298e-01],\n",
      "          [ 9.0535e-02,  4.1888e-02, -3.8227e-02],\n",
      "          [ 5.8382e-02,  9.4344e-02,  5.1291e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.9654e-02, -4.7697e-02,  1.1477e-02],\n",
      "          [-4.9369e-02,  6.1653e-03,  5.9643e-02],\n",
      "          [ 1.1690e-02,  6.7204e-02,  5.9075e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1386e-01,  5.8328e-02, -9.6813e-02],\n",
      "          [ 8.8782e-02,  1.2896e-01,  1.8835e-02],\n",
      "          [ 4.1947e-02,  1.3004e-01,  9.5878e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 8.4729e-02,  1.4377e-01,  2.7908e-02],\n",
      "          [-4.4239e-02,  9.5707e-02,  1.1842e-01],\n",
      "          [-1.4937e-01, -3.6929e-02,  7.5838e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.6790e-02, -1.1728e-01, -1.0453e-01],\n",
      "          [ 5.7714e-02, -8.5145e-03, -1.8676e-02],\n",
      "          [ 8.8229e-02,  9.8636e-02,  8.5936e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6692e-02,  3.0884e-02,  3.1190e-02],\n",
      "          [ 1.8585e-02,  3.6434e-03, -7.9408e-03],\n",
      "          [-1.9970e-02, -3.4315e-02, -3.0893e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8067e-01, -8.3439e-02, -2.8472e-01],\n",
      "          [ 2.4876e-01,  1.0114e-01, -1.3138e-01],\n",
      "          [ 1.7080e-01,  2.5745e-01,  1.1261e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 6.8199e-02,  1.3544e-01,  6.6222e-02],\n",
      "          [ 1.4912e-01,  1.0338e-01, -6.5972e-02],\n",
      "          [ 1.1043e-01, -2.4245e-02, -1.3746e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 9.5139e-02, -5.1679e-02, -1.4145e-01],\n",
      "          [ 1.3272e-01,  3.0142e-02, -9.1955e-02],\n",
      "          [ 1.0074e-01,  1.2720e-01,  3.9967e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.8390e-02,  1.4765e-02, -5.2926e-02],\n",
      "          [ 4.5355e-02,  4.2203e-02, -1.3151e-02],\n",
      "          [ 2.6318e-02,  5.4586e-02,  3.0057e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 8.7616e-02,  6.6402e-02, -5.6720e-02],\n",
      "          [ 3.8451e-02,  1.1855e-01,  5.4580e-02],\n",
      "          [-3.0724e-02,  6.8294e-02,  8.0699e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.5604e-02,  1.0210e-01,  3.6948e-02],\n",
      "          [-3.7013e-02,  5.6086e-02,  8.6270e-02],\n",
      "          [-1.1326e-01, -4.7307e-02,  4.4069e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.5261e-02, -4.1740e-02,  2.7746e-02],\n",
      "          [-5.5750e-02,  1.2849e-02,  6.9800e-02],\n",
      "          [ 8.7119e-03,  7.4173e-02,  6.6217e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.3636e-02,  1.2071e-01,  1.0697e-01],\n",
      "          [-7.7395e-02,  4.2476e-03,  9.8396e-02],\n",
      "          [-1.3510e-01, -1.0499e-01,  4.4929e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1800e-01,  2.3756e-01,  1.1230e-01],\n",
      "          [ 2.6088e-01,  1.8680e-01, -1.1389e-01],\n",
      "          [ 2.2502e-01, -4.0801e-03, -2.2951e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6987e-02,  1.0020e-01,  6.8234e-02],\n",
      "          [ 6.1836e-02,  1.7426e-01,  8.9939e-02],\n",
      "          [ 9.6817e-02,  1.5083e-01,  5.8916e-02]]],\n",
      "\n",
      "\n",
      "        [[[-9.2998e-02, -2.4959e-01, -2.1436e-01],\n",
      "          [ 7.6391e-02, -3.3040e-02, -1.1275e-02],\n",
      "          [ 2.1076e-01,  2.2500e-01,  2.0398e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.4510e-04, -1.9241e-04, -2.1496e-04],\n",
      "          [-1.7573e-04, -2.0263e-04, -2.0060e-04],\n",
      "          [-2.3127e-04, -2.1002e-04, -1.3508e-04]]],\n",
      "\n",
      "\n",
      "        [[[-4.3411e-02,  1.3897e-02,  4.5379e-02],\n",
      "          [-1.1168e-02,  5.4806e-02,  5.4221e-02],\n",
      "          [ 4.2901e-02,  6.9267e-02,  3.2955e-02]]],\n",
      "\n",
      "\n",
      "        [[[-7.7574e-02, -6.1234e-02,  1.5442e-02],\n",
      "          [-5.8835e-02,  1.3192e-02,  7.4729e-02],\n",
      "          [ 2.8136e-02,  8.9692e-02,  7.1137e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.4764e-02,  4.1653e-02, -3.4138e-02],\n",
      "          [ 3.8244e-02,  8.1585e-02,  3.2829e-02],\n",
      "          [ 7.3530e-03,  6.6217e-02,  5.7212e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.9670e-02, -2.4965e-02, -7.1611e-02],\n",
      "          [ 6.7087e-02,  1.4823e-02, -4.7753e-02],\n",
      "          [ 5.1959e-02,  6.3719e-02,  1.8196e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.3841e-02,  6.1466e-02,  6.4031e-02],\n",
      "          [-1.0743e-02, -3.8773e-04,  2.5869e-02],\n",
      "          [-6.5023e-02, -6.2939e-02, -3.5582e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3943e-01,  1.6876e-01,  1.8083e-02],\n",
      "          [ 1.9388e-01,  7.4624e-02, -1.3675e-01],\n",
      "          [ 1.1374e-01, -8.3057e-02, -1.7336e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.0125e-01,  2.1600e-02,  9.4273e-02],\n",
      "          [-2.1297e-02,  1.1768e-01,  1.1425e-01],\n",
      "          [ 1.0406e-01,  1.5078e-01,  5.9618e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.5188e-01, -1.3615e-01,  2.8668e-03],\n",
      "          [-8.1358e-02,  4.1885e-02,  1.3565e-01],\n",
      "          [ 1.0467e-01,  1.7779e-01,  1.2179e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9927e-01,  2.0666e-01,  2.0770e-01],\n",
      "          [ 7.9660e-03, -1.2054e-02, -2.7127e-02],\n",
      "          [-1.9905e-01, -2.1196e-01, -1.7836e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.2953e-01, -1.0199e-01,  3.0846e-02],\n",
      "          [-1.0019e-01,  2.4692e-02,  1.2935e-01],\n",
      "          [ 4.5284e-02,  1.5062e-01,  1.1939e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4314e-01,  5.5458e-02, -1.5229e-01],\n",
      "          [ 1.2143e-01,  1.6325e-01,  9.7423e-03],\n",
      "          [ 4.5254e-02,  1.6656e-01,  1.1699e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.6293e-02,  4.4712e-02,  4.6797e-02],\n",
      "          [-1.0713e-02, -1.4224e-03,  1.9276e-02],\n",
      "          [-4.6036e-02, -4.6472e-02, -2.3863e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.3605e-02,  1.4055e-01,  1.2633e-01],\n",
      "          [-7.2662e-02,  2.7382e-03,  9.7081e-02],\n",
      "          [-1.5232e-01, -1.3805e-01, -2.1452e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0737e-01,  1.1223e-01,  1.1251e-01],\n",
      "          [ 5.9722e-03, -6.5135e-03, -1.7373e-02],\n",
      "          [-1.0742e-01, -1.1481e-01, -9.5571e-02]]],\n",
      "\n",
      "\n",
      "        [[[-9.0279e-02, -1.5163e-01, -1.2530e-01],\n",
      "          [ 1.8290e-02, -2.5213e-02,  6.5609e-03],\n",
      "          [ 1.4319e-01,  1.4572e-01,  1.2471e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4199e-02,  3.7503e-02,  2.8009e-02],\n",
      "          [-2.2925e-02,  7.6597e-03,  3.1468e-02],\n",
      "          [-4.2364e-02, -2.7036e-02,  8.8843e-03]]]], device='cuda:0'), 'features.0.bias': tensor([ 1.4411e-02,  1.4795e-05,  1.6375e-02,  2.1176e-02,  2.5463e-02,\n",
      "         1.1475e-02,  2.6977e-02,  3.6434e-02,  2.7311e-02,  3.5594e-04,\n",
      "         1.9324e-02,  2.0775e-02,  2.6632e-02,  1.6441e-02,  3.9828e-03,\n",
      "         2.1111e-03,  1.8152e-02,  2.1502e-02,  4.2505e-04,  3.1926e-02,\n",
      "         5.4037e-03,  2.7017e-02,  1.6142e-02,  7.7799e-04,  2.0163e-02,\n",
      "         2.1211e-02,  1.4456e-02,  1.6699e-02, -4.3874e-04,  4.8087e-03,\n",
      "         4.3452e-03,  1.3903e-02,  1.5435e-02, -3.9260e-03,  2.1038e-02,\n",
      "         7.4678e-03,  1.0889e-02,  3.1640e-02,  9.6830e-03,  4.3595e-03,\n",
      "         6.9016e-03,  1.8241e-03,  1.1876e-02,  1.0286e-02,  6.1752e-02,\n",
      "         3.0102e-02,  4.3921e-02,  4.6229e-04,  8.7481e-03,  1.6838e-02,\n",
      "         1.0597e-02,  4.9015e-03,  1.0206e-02,  4.7889e-02,  1.7870e-02,\n",
      "         3.4352e-02,  2.6904e-02,  2.6102e-02,  1.3654e-02,  5.6792e-03,\n",
      "         1.3637e-02,  1.4101e-02,  1.8714e-02,  2.7885e-03], device='cuda:0'), 'features.3.weight': tensor([[[[-4.8403e-03, -3.1887e-03, -5.4203e-03],\n",
      "          [-1.2538e-02, -8.9866e-03, -1.8661e-03],\n",
      "          [-9.7007e-03, -6.7100e-03, -8.4034e-04]],\n",
      "\n",
      "         [[ 2.2655e-07, -2.1797e-05,  3.7920e-06],\n",
      "          [ 2.9885e-06, -3.2005e-05, -2.7124e-05],\n",
      "          [-5.2590e-07, -1.6086e-05, -1.0076e-05]],\n",
      "\n",
      "         [[ 4.0047e-03, -7.7275e-03,  7.0390e-04],\n",
      "          [ 5.1208e-03, -1.0335e-02, -1.0598e-02],\n",
      "          [ 2.2520e-03, -5.5660e-03, -4.7676e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.7917e-03, -6.4399e-03,  2.9200e-04],\n",
      "          [-1.1113e-02, -8.8980e-03, -7.5131e-03],\n",
      "          [-6.6307e-03, -1.6908e-03, -2.0066e-03]],\n",
      "\n",
      "         [[-5.8180e-03, -1.8487e-03, -5.6554e-03],\n",
      "          [-1.5737e-02, -8.3862e-03, -1.5660e-03],\n",
      "          [-1.2349e-02, -6.9742e-03, -9.7357e-04]],\n",
      "\n",
      "         [[ 3.1838e-03, -1.3605e-03, -7.1175e-05],\n",
      "          [ 3.5525e-03, -1.3532e-03, -2.3583e-03],\n",
      "          [ 2.0715e-03, -1.1945e-03, -1.4951e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 8.9143e-03, -6.5550e-04, -1.2115e-02],\n",
      "          [-2.0605e-03, -2.7964e-03,  1.3192e-05],\n",
      "          [ 4.9976e-03,  7.3110e-03,  5.2796e-03]],\n",
      "\n",
      "         [[ 1.9884e-05,  4.4601e-05,  2.5079e-05],\n",
      "          [ 5.4704e-05,  3.3239e-05, -2.8496e-05],\n",
      "          [-2.0387e-05, -3.0697e-05, -2.1389e-05]],\n",
      "\n",
      "         [[ 7.4187e-03,  1.5228e-02,  8.1970e-03],\n",
      "          [ 1.7145e-02,  9.7654e-03, -1.1001e-02],\n",
      "          [-8.5317e-03, -1.1636e-02, -7.7549e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 9.9965e-03,  1.7327e-02,  1.4673e-02],\n",
      "          [ 2.0802e-02,  1.6166e-02, -2.7753e-03],\n",
      "          [-2.9093e-03, -6.3799e-03, -5.2529e-03]],\n",
      "\n",
      "         [[ 9.9794e-03, -2.2813e-03, -1.5277e-02],\n",
      "          [-2.0848e-03, -4.5670e-03, -1.4097e-03],\n",
      "          [ 6.4494e-03,  7.8177e-03,  5.5775e-03]],\n",
      "\n",
      "         [[ 1.6745e-03,  2.5334e-03,  5.4325e-04],\n",
      "          [ 2.2602e-03,  4.0587e-04, -3.2070e-03],\n",
      "          [-2.2581e-03, -2.8106e-03, -1.5071e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 6.0487e-03, -3.0048e-03, -2.4802e-02],\n",
      "          [ 1.5971e-02, -1.8038e-02, -2.0068e-02],\n",
      "          [-1.3177e-02, -1.4398e-02, -9.2223e-04]],\n",
      "\n",
      "         [[-1.5563e-05, -4.6083e-05, -1.2708e-05],\n",
      "          [-7.2577e-05, -6.3996e-06, -2.4171e-05],\n",
      "          [ 2.3764e-05,  1.4107e-05, -3.0979e-05]],\n",
      "\n",
      "         [[-3.9524e-03, -1.3660e-02, -5.0167e-03],\n",
      "          [-2.5693e-02, -3.6203e-03, -1.0249e-02],\n",
      "          [ 5.0494e-03,  2.6068e-03, -1.2988e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.5268e-03, -8.7575e-03,  6.3009e-03],\n",
      "          [-6.7802e-03,  1.5758e-02,  3.8424e-03],\n",
      "          [ 3.1909e-02,  1.9150e-02, -6.4652e-03]],\n",
      "\n",
      "         [[ 4.5680e-03, -5.6996e-03, -2.8861e-02],\n",
      "          [ 1.3196e-02, -2.4802e-02, -2.3931e-02],\n",
      "          [-1.8548e-02, -1.9530e-02, -2.5410e-03]],\n",
      "\n",
      "         [[ 2.6687e-04, -1.8445e-04, -1.7208e-03],\n",
      "          [-5.1040e-03, -2.9144e-03, -4.4589e-03],\n",
      "          [-1.6840e-03, -2.4750e-03, -3.6871e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-5.7209e-03, -5.9104e-03, -1.1135e-02],\n",
      "          [-1.2432e-03, -9.9570e-03, -1.0475e-02],\n",
      "          [-2.7728e-03, -1.2161e-02, -4.7735e-03]],\n",
      "\n",
      "         [[ 4.1369e-06, -2.0253e-05, -2.2505e-05],\n",
      "          [-3.3035e-05, -3.4840e-05, -1.9913e-05],\n",
      "          [-1.8399e-05, -1.3046e-05, -1.8002e-05]],\n",
      "\n",
      "         [[ 4.5018e-03, -4.4292e-03, -8.2757e-03],\n",
      "          [-9.4176e-03, -1.2081e-02, -8.3407e-03],\n",
      "          [-6.2002e-03, -5.3457e-03, -8.1554e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.5126e-03, -9.8297e-03, -3.9052e-03],\n",
      "          [-1.2248e-02, -3.1266e-03,  1.4035e-04],\n",
      "          [ 6.8642e-05,  7.3433e-03, -1.5629e-03]],\n",
      "\n",
      "         [[-7.7654e-03, -6.3476e-03, -1.1654e-02],\n",
      "          [-4.1317e-03, -1.2593e-02, -1.1963e-02],\n",
      "          [-5.7597e-03, -1.5461e-02, -5.7072e-03]],\n",
      "\n",
      "         [[ 2.6116e-03,  9.1131e-04, -1.6773e-03],\n",
      "          [-3.6937e-04, -2.3866e-03, -2.8893e-03],\n",
      "          [-1.3145e-03, -2.5571e-03, -2.7993e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5252e-03, -1.6862e-03, -2.4289e-03],\n",
      "          [ 5.2424e-03,  3.7381e-03,  1.1979e-04],\n",
      "          [ 3.1187e-03,  5.5884e-03,  5.1839e-03]],\n",
      "\n",
      "         [[ 1.1870e-06,  1.0173e-05,  1.2285e-05],\n",
      "          [-5.3062e-06, -2.1213e-06,  4.9442e-06],\n",
      "          [ 9.2332e-06,  4.7829e-07, -5.8961e-06]],\n",
      "\n",
      "         [[-1.0963e-04,  3.6688e-03,  5.0512e-03],\n",
      "          [-2.1698e-03, -1.2722e-03,  1.8330e-03],\n",
      "          [ 3.6591e-03,  6.7922e-04, -2.0772e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.6895e-03,  2.2899e-03,  1.7993e-03],\n",
      "          [-1.1057e-03, -9.3579e-04, -5.0497e-04],\n",
      "          [ 1.6202e-03, -9.6525e-04, -1.6052e-03]],\n",
      "\n",
      "         [[ 1.6776e-03, -2.0708e-03, -2.9059e-03],\n",
      "          [ 6.9216e-03,  4.8758e-03,  2.8759e-04],\n",
      "          [ 4.1371e-03,  7.3062e-03,  6.7043e-03]],\n",
      "\n",
      "         [[-4.0132e-04,  7.0026e-04,  1.3560e-03],\n",
      "          [-6.8137e-04, -4.9806e-04,  4.9454e-04],\n",
      "          [ 8.9890e-04,  4.1342e-04, -3.9208e-04]]],\n",
      "\n",
      "\n",
      "        [[[-1.8742e-03, -2.0168e-03,  6.1356e-04],\n",
      "          [-2.1343e-03, -2.9887e-03, -4.4057e-05],\n",
      "          [-5.2048e-04, -1.3138e-03, -1.4900e-03]],\n",
      "\n",
      "         [[ 2.8010e-06,  5.2973e-06, -7.0296e-07],\n",
      "          [ 5.0708e-07,  9.9035e-06,  8.4327e-06],\n",
      "          [-1.0992e-06,  8.2400e-06,  1.1811e-05]],\n",
      "\n",
      "         [[ 1.1534e-03,  2.4983e-03, -9.0064e-05],\n",
      "          [ 1.3020e-04,  3.8713e-03,  3.7766e-03],\n",
      "          [-6.7551e-04,  2.7172e-03,  4.8197e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.5930e-04, -5.7651e-04, -9.4595e-04],\n",
      "          [-3.8073e-04,  2.2629e-04, -4.4347e-04],\n",
      "          [-1.8515e-04,  1.0646e-03,  1.1418e-03]],\n",
      "\n",
      "         [[-2.3128e-03, -2.3556e-03,  1.2134e-03],\n",
      "          [-2.5134e-03, -3.3346e-03,  5.4165e-04],\n",
      "          [-5.0107e-04, -1.4621e-03, -1.7323e-03]],\n",
      "\n",
      "         [[ 3.1570e-04,  8.7366e-04,  1.2020e-04],\n",
      "          [ 1.0318e-05,  1.0502e-03,  1.2037e-03],\n",
      "          [-3.4873e-04,  4.3223e-04,  1.3890e-03]]]], device='cuda:0'), 'features.3.bias': tensor([-2.4130e-03,  1.1856e-02,  2.6067e-04, -1.2973e-02,  8.7408e-03,\n",
      "        -5.1146e-03,  3.4111e-03, -1.5206e-03,  3.6786e-03,  5.3294e-03,\n",
      "        -4.4112e-03,  4.1189e-03, -4.3031e-03, -9.5696e-03, -6.1474e-03,\n",
      "         4.3488e-03, -6.2730e-03,  2.1643e-03,  1.5593e-03, -1.1575e-02,\n",
      "         3.3273e-03, -2.2214e-03, -6.1199e-03,  2.7329e-03,  3.5557e-03,\n",
      "         2.6256e-03, -4.7810e-04,  1.2230e-03, -5.6209e-06, -7.5661e-04,\n",
      "        -1.1068e-03, -1.9451e-02, -7.1812e-03, -3.7159e-03,  8.8192e-03,\n",
      "        -1.7527e-03,  1.8890e-03, -3.6420e-03,  7.0317e-03,  4.2465e-03,\n",
      "        -5.0246e-03,  9.3504e-04, -9.5722e-05, -6.0773e-03, -2.9452e-03,\n",
      "         3.4107e-03, -9.5432e-04, -4.4123e-03, -3.1802e-03, -1.9751e-02,\n",
      "        -7.8335e-09,  2.8158e-03,  1.7911e-02, -3.1994e-04,  3.8808e-04,\n",
      "        -4.9633e-03,  1.4769e-03, -2.6153e-03, -6.5217e-03,  8.1088e-08,\n",
      "        -7.1085e-03, -2.2692e-02, -2.2534e-03, -7.3154e-03, -5.8532e-04,\n",
      "        -3.0485e-03, -9.3378e-03,  9.7504e-03, -1.2618e-02, -8.6829e-03,\n",
      "         3.6579e-03, -1.3951e-02, -3.0193e-03,  1.1058e-03,  3.3388e-02,\n",
      "         2.1307e-03,  2.0446e-03, -2.8062e-03, -5.0625e-03,  8.8290e-03,\n",
      "        -2.1586e-03,  7.1678e-03, -6.3478e-03, -5.0613e-03, -6.1018e-03,\n",
      "        -8.9727e-04,  1.8296e-04, -1.5283e-02, -4.5687e-03, -1.9211e-03,\n",
      "        -7.9114e-03,  1.0334e-03, -5.8948e-05, -1.3731e-02,  9.6835e-03,\n",
      "        -1.1003e-02, -5.3827e-03,  1.8731e-02, -3.3318e-03, -4.4580e-05,\n",
      "         8.9567e-05, -1.2530e-02,  2.6594e-04,  2.5371e-03, -4.5291e-03,\n",
      "         8.0828e-04, -9.8598e-03,  4.9630e-03, -1.1952e-03, -1.4463e-02,\n",
      "        -2.0435e-03, -1.9681e-02, -5.4941e-03,  1.1528e-03,  9.6258e-04,\n",
      "         6.2221e-04,  1.0445e-03,  4.9803e-03,  3.5374e-03,  5.8377e-06,\n",
      "        -5.4302e-04, -4.1978e-03, -2.8752e-02,  2.5587e-03, -2.2268e-02,\n",
      "        -1.5501e-03, -3.4394e-05,  1.7951e-03], device='cuda:0'), 'features.6.weight': tensor([[[[-4.9773e-03, -1.7135e-03,  8.3199e-03],\n",
      "          [ 1.0188e-02,  7.5571e-03,  1.3097e-02],\n",
      "          [ 8.4289e-03,  8.0197e-03,  4.8862e-03]],\n",
      "\n",
      "         [[ 1.4464e-02,  8.9992e-03, -4.1721e-03],\n",
      "          [ 2.7492e-03, -1.3956e-02, -1.1746e-02],\n",
      "          [ 6.7885e-04, -1.1730e-02, -6.7134e-03]],\n",
      "\n",
      "         [[ 2.1704e-02, -5.8049e-03, -1.6153e-02],\n",
      "          [-3.6409e-04, -2.3748e-02, -1.2071e-02],\n",
      "          [ 1.2067e-02, -9.7302e-03,  1.0890e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4066e-03, -8.2961e-03,  7.2787e-05],\n",
      "          [ 9.9125e-04, -1.0272e-03,  6.3746e-03],\n",
      "          [ 8.7242e-03,  3.2200e-03,  7.0620e-03]],\n",
      "\n",
      "         [[ 1.0970e-03, -2.2020e-03, -1.4827e-03],\n",
      "          [ 5.1235e-03,  5.9464e-04, -2.4266e-03],\n",
      "          [ 2.6463e-03,  3.4380e-03, -6.9476e-04]],\n",
      "\n",
      "         [[ 4.7431e-05,  1.8618e-03,  1.4547e-03],\n",
      "          [ 5.2886e-04,  1.4270e-03,  3.0609e-03],\n",
      "          [-1.0771e-04, -1.1931e-03,  3.2746e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6548e-03,  1.4849e-03, -2.2685e-03],\n",
      "          [ 3.4134e-03, -6.5054e-04,  4.5637e-03],\n",
      "          [-4.0296e-03, -7.9976e-03,  4.1919e-03]],\n",
      "\n",
      "         [[-1.0859e-03, -2.5598e-03,  6.0107e-04],\n",
      "          [-4.5185e-04, -2.5251e-03, -1.0403e-02],\n",
      "          [ 1.1974e-02,  1.2401e-02,  5.2085e-04]],\n",
      "\n",
      "         [[ 5.5231e-03, -3.4197e-03, -1.4433e-02],\n",
      "          [-5.4016e-04,  5.9075e-03, -6.9575e-03],\n",
      "          [ 6.2003e-03,  2.0737e-02,  1.5064e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.3562e-03, -2.6273e-03, -9.0968e-03],\n",
      "          [ 5.2388e-04,  1.8236e-03, -1.1493e-04],\n",
      "          [-2.6712e-03,  2.2920e-03,  9.9674e-03]],\n",
      "\n",
      "         [[-1.6470e-03,  2.1730e-04,  2.1781e-03],\n",
      "          [ 1.5373e-03, -2.7602e-04, -4.4965e-05],\n",
      "          [-7.8155e-04, -1.9373e-03, -1.2854e-03]],\n",
      "\n",
      "         [[-3.3989e-05,  1.2916e-03,  5.3246e-04],\n",
      "          [ 4.3644e-04,  1.4191e-03,  2.0368e-03],\n",
      "          [-5.8887e-04, -2.5687e-03, -7.8852e-04]]],\n",
      "\n",
      "\n",
      "        [[[-1.5600e-03,  1.8281e-03, -6.0207e-04],\n",
      "          [ 1.7609e-03,  3.5796e-03,  2.0031e-03],\n",
      "          [ 1.3329e-03, -6.2565e-03, -8.2658e-03]],\n",
      "\n",
      "         [[ 5.7364e-03,  4.3416e-03,  7.7107e-04],\n",
      "          [-8.1374e-04, -3.2291e-03,  1.3675e-03],\n",
      "          [ 4.6890e-03,  3.9857e-03,  1.0462e-02]],\n",
      "\n",
      "         [[ 8.4484e-03,  1.0047e-02, -3.8946e-03],\n",
      "          [ 1.0471e-02, -4.6329e-03,  9.3977e-03],\n",
      "          [-5.4279e-04, -1.7916e-02, -9.4715e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.3698e-03,  3.6842e-03, -2.0949e-04],\n",
      "          [ 4.2624e-03, -1.9957e-03,  3.1990e-03],\n",
      "          [-1.0300e-03, -9.0674e-03, -6.5412e-03]],\n",
      "\n",
      "         [[-1.1178e-03, -2.4096e-03, -1.1971e-03],\n",
      "          [-2.1514e-04, -6.8830e-04, -1.7266e-03],\n",
      "          [ 3.0229e-03,  3.9879e-03,  1.9828e-03]],\n",
      "\n",
      "         [[-4.8064e-04, -6.8982e-04, -1.1202e-03],\n",
      "          [ 6.3997e-06,  2.7606e-03,  1.5937e-03],\n",
      "          [-8.0532e-04, -2.0890e-04, -6.9032e-04]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 4.0466e-03,  4.1997e-03,  3.7080e-03],\n",
      "          [-4.2928e-03, -6.8969e-03, -1.0543e-02],\n",
      "          [ 1.6704e-03,  3.3010e-04,  3.0774e-03]],\n",
      "\n",
      "         [[ 3.6096e-03,  3.0592e-03,  6.9915e-03],\n",
      "          [ 1.6867e-03,  1.7775e-03,  9.2901e-04],\n",
      "          [ 2.9885e-03, -5.6064e-04, -4.1906e-03]],\n",
      "\n",
      "         [[ 1.6896e-02,  2.2099e-02,  1.9602e-02],\n",
      "          [-5.3374e-04, -2.2815e-02, -3.0492e-02],\n",
      "          [ 7.3108e-03,  7.9947e-03,  8.2649e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 8.0332e-03,  1.0438e-02,  6.0767e-03],\n",
      "          [-2.4948e-03, -1.3937e-02, -1.5189e-02],\n",
      "          [ 2.3193e-03,  3.3223e-03,  6.6825e-03]],\n",
      "\n",
      "         [[-1.0535e-03, -2.7509e-03, -4.0254e-03],\n",
      "          [ 1.1994e-03,  6.7530e-03,  5.5813e-03],\n",
      "          [-1.3646e-03, -1.6400e-03, -1.4443e-03]],\n",
      "\n",
      "         [[-4.3717e-04,  7.8075e-04,  1.3680e-03],\n",
      "          [-8.2042e-04, -9.5514e-05, -4.1872e-04],\n",
      "          [-3.4537e-04, -2.7422e-04,  6.6803e-05]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6288e-04, -1.9262e-03, -5.1840e-03],\n",
      "          [ 7.2037e-03,  2.3892e-03, -4.6173e-03],\n",
      "          [ 8.8788e-03, -7.3787e-04, -3.6420e-03]],\n",
      "\n",
      "         [[-3.0247e-03,  1.0714e-03,  6.1701e-03],\n",
      "          [-9.6988e-03,  4.7786e-03,  9.4620e-03],\n",
      "          [ 2.1457e-03,  8.6017e-03, -2.1400e-03]],\n",
      "\n",
      "         [[-7.4312e-03,  4.2375e-03,  8.8381e-03],\n",
      "          [-6.0967e-03,  1.0091e-02,  4.1311e-03],\n",
      "          [-7.9873e-04, -1.0639e-03, -2.0994e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.9773e-04,  9.8196e-04, -6.8190e-04],\n",
      "          [ 4.1333e-03,  1.2189e-03, -5.4611e-03],\n",
      "          [ 4.0867e-03, -2.5306e-03, -8.9686e-03]],\n",
      "\n",
      "         [[-1.8144e-03,  9.1453e-04,  9.8701e-04],\n",
      "          [-1.6445e-03,  3.1073e-05, -6.7916e-05],\n",
      "          [-5.5242e-04, -5.0282e-05, -6.9598e-04]],\n",
      "\n",
      "         [[-5.0955e-04, -1.3068e-03, -3.8581e-04],\n",
      "          [ 8.6803e-04, -2.4583e-04,  1.4834e-04],\n",
      "          [ 1.8069e-03, -4.0143e-04, -4.9914e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 2.5508e-03,  7.6774e-04,  6.8922e-04],\n",
      "          [ 4.5392e-04, -2.2434e-03, -2.6490e-03],\n",
      "          [ 4.5487e-03,  4.7027e-03, -2.0540e-03]],\n",
      "\n",
      "         [[-2.2900e-03, -3.3522e-03, -1.7954e-03],\n",
      "          [-2.7610e-03,  1.7935e-03,  7.8911e-03],\n",
      "          [-2.9479e-03, -8.6193e-04, -1.3640e-03]],\n",
      "\n",
      "         [[-4.0321e-03, -6.1588e-03,  5.7247e-03],\n",
      "          [-6.1606e-03,  3.1058e-03,  9.0665e-03],\n",
      "          [ 4.8740e-03,  3.2215e-03, -3.8484e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.0035e-03, -1.7623e-03,  3.1705e-03],\n",
      "          [-8.1680e-04,  4.4519e-04, -5.7258e-04],\n",
      "          [ 5.2303e-03,  4.8839e-03, -1.3569e-03]],\n",
      "\n",
      "         [[-1.6083e-04,  7.9122e-04,  1.4996e-03],\n",
      "          [-1.4247e-03, -1.6095e-03, -1.3219e-03],\n",
      "          [-1.4667e-03, -6.3125e-04, -6.2089e-04]],\n",
      "\n",
      "         [[ 6.9881e-04, -5.7940e-04, -5.7509e-04],\n",
      "          [ 5.8764e-04, -4.6790e-05, -1.0548e-04],\n",
      "          [ 3.2747e-05, -9.6554e-05, -1.1585e-05]]]], device='cuda:0'), 'features.6.bias': tensor([ 1.2821e-02,  3.6596e-03,  3.7912e-03,  8.8750e-04,  1.3253e-03,\n",
      "         8.2878e-04,  2.2434e-03,  2.7238e-04,  2.7214e-03,  4.0087e-03,\n",
      "         2.3812e-03,  1.0393e-02,  2.5997e-03,  2.1422e-03,  1.8890e-05,\n",
      "         6.7187e-03,  1.0958e-03,  1.7501e-03,  6.4848e-03,  3.5348e-04,\n",
      "         6.4973e-03,  2.6003e-03,  5.0795e-03,  1.9751e-03,  1.5659e-03,\n",
      "         3.0259e-03,  6.9087e-04, -1.1207e-04,  3.9310e-03,  8.9909e-03,\n",
      "         1.4548e-02,  3.6325e-03,  3.7328e-03,  9.5707e-04,  5.1665e-03,\n",
      "         2.1508e-03,  7.2251e-03,  3.4869e-03,  2.3752e-03,  2.7667e-03,\n",
      "         5.9171e-03,  2.0706e-03,  9.0740e-04,  2.1764e-03, -1.4905e-03,\n",
      "        -7.9455e-04,  2.8047e-03,  4.2123e-04,  2.8781e-03,  2.3596e-03,\n",
      "         4.8021e-03,  7.6960e-03, -3.6041e-04,  6.1474e-03,  2.0667e-03,\n",
      "        -5.1654e-04,  5.0857e-03,  3.1073e-03,  1.5072e-03,  2.3772e-03,\n",
      "         6.4622e-03,  1.3195e-03,  2.7148e-03,  8.6170e-04,  1.0592e-03,\n",
      "         9.3112e-04,  4.8138e-03,  5.6933e-03,  6.5363e-03,  5.8259e-06,\n",
      "         1.8120e-03,  3.1353e-03,  1.1447e-02, -4.3201e-04,  1.4057e-03,\n",
      "         7.9746e-03,  5.3370e-03,  9.0164e-04,  1.9798e-03, -2.1803e-03,\n",
      "         2.7342e-03,  5.1308e-05, -7.3877e-05,  3.5903e-04, -1.5314e-04,\n",
      "         3.4973e-04,  1.2979e-02,  2.5340e-03,  5.4108e-03,  3.4048e-03,\n",
      "         8.0592e-04,  6.6879e-04,  2.5408e-03,  7.4294e-03,  2.4206e-03,\n",
      "         7.3592e-04,  4.4889e-04,  4.9715e-03,  1.0604e-03,  8.5849e-04,\n",
      "         7.9341e-04,  4.1551e-04,  1.5300e-03,  8.4941e-04,  5.8242e-03,\n",
      "         1.3211e-03, -3.7391e-04,  1.8081e-04,  1.7740e-03,  2.2676e-03,\n",
      "         3.1384e-03,  1.2623e-03,  5.9266e-03,  2.5322e-03,  5.6826e-04,\n",
      "         4.3764e-03,  2.0655e-03,  6.9669e-03,  1.3091e-05,  1.0448e-04,\n",
      "         3.0974e-04,  4.5598e-03,  2.0578e-03,  6.7365e-04,  4.2131e-05,\n",
      "         4.3687e-03,  2.9576e-03,  3.0046e-03,  5.7962e-03,  2.9272e-03,\n",
      "         2.0780e-03,  1.1906e-02,  1.3626e-03,  8.0131e-04,  3.8678e-03,\n",
      "         4.6940e-04,  1.4426e-03,  8.5321e-04,  1.0645e-03,  5.4165e-03,\n",
      "         6.1650e-03,  3.8201e-03,  1.1023e-03,  1.0763e-02,  1.9173e-03,\n",
      "         1.6189e-02,  1.3481e-02,  1.0575e-03,  2.4225e-03,  4.2176e-03,\n",
      "         2.0542e-03,  6.0270e-03,  1.9114e-03,  1.7247e-03,  2.2255e-03,\n",
      "         5.3983e-04,  1.1181e-03,  4.8873e-03,  5.4426e-03,  4.8922e-03,\n",
      "         2.8192e-04,  4.7822e-03,  4.2726e-03,  3.2672e-03,  1.5935e-04,\n",
      "         7.0530e-03,  1.8237e-03,  2.9082e-03,  2.7611e-05,  1.0265e-03,\n",
      "         3.1189e-03,  1.0492e-03,  4.3784e-03, -1.5563e-03,  2.0114e-04,\n",
      "         2.7216e-03,  8.8929e-03,  5.1303e-03,  2.2843e-03,  9.2291e-04,\n",
      "         1.3157e-02,  1.2770e-04,  8.0138e-04,  9.1123e-04,  7.1245e-03,\n",
      "         3.0712e-03,  7.4254e-03,  4.6334e-03,  7.4766e-03,  5.4034e-03,\n",
      "         7.0660e-03,  1.2700e-04,  2.5460e-03,  1.3991e-02,  1.2925e-03,\n",
      "         8.2217e-05,  2.6344e-03, -2.9101e-06,  1.1722e-03,  7.2643e-04,\n",
      "         1.3584e-03,  1.6689e-03,  5.0962e-04,  6.0983e-03,  2.5805e-03,\n",
      "         3.1935e-03,  6.8188e-03,  3.2723e-03,  2.6479e-03,  2.4357e-04,\n",
      "         2.2014e-04, -1.7855e-06,  1.4329e-03,  6.9324e-03,  7.6158e-03,\n",
      "         3.8739e-03,  9.8625e-04,  1.2147e-03,  8.0398e-03,  4.6553e-04,\n",
      "         7.9169e-03,  3.3927e-03,  1.6255e-04,  7.9739e-05,  2.3155e-03,\n",
      "         4.5479e-03,  3.2599e-04,  6.3293e-03,  5.9711e-03,  5.1702e-03,\n",
      "         3.5795e-05,  4.1764e-05,  4.9366e-03,  7.4431e-04,  7.1479e-03,\n",
      "         4.7921e-03,  1.2111e-03, -2.2659e-03,  1.1729e-03,  1.0974e-02,\n",
      "         2.2974e-03,  1.7556e-03,  1.9873e-03,  3.3377e-03,  4.8394e-03,\n",
      "        -1.2717e-03,  1.4665e-03, -3.4005e-05,  5.7420e-03,  1.2961e-03,\n",
      "         2.3518e-03,  9.8518e-03,  6.5027e-04,  3.6600e-04,  1.2164e-03,\n",
      "         5.0322e-04], device='cuda:0'), 'features.8.weight': tensor([[[[-1.7899e-04,  1.9779e-05, -1.2197e-04],\n",
      "          [-3.0813e-04,  8.3287e-04,  3.5309e-04],\n",
      "          [-2.5397e-04,  5.9915e-05,  1.8843e-05]],\n",
      "\n",
      "         [[-1.7968e-04, -1.5422e-04, -1.9442e-04],\n",
      "          [-7.2364e-05,  1.9821e-05,  8.3491e-05],\n",
      "          [-8.2063e-05, -5.9931e-05,  3.9925e-05]],\n",
      "\n",
      "         [[-6.9522e-05,  7.7447e-05,  6.8449e-05],\n",
      "          [-7.3394e-05,  3.9152e-05,  7.0276e-05],\n",
      "          [-5.1019e-05, -1.4331e-04, -6.0500e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.4060e-04, -1.4701e-05,  6.3244e-05],\n",
      "          [-1.8482e-04, -1.0891e-04, -1.3386e-04],\n",
      "          [-1.7536e-04, -2.2669e-05, -1.0227e-04]],\n",
      "\n",
      "         [[ 3.0199e-04,  4.2587e-04, -1.2001e-04],\n",
      "          [ 4.1063e-04,  1.3485e-04, -1.6272e-04],\n",
      "          [-7.2203e-05, -2.2584e-04, -1.3950e-04]],\n",
      "\n",
      "         [[ 2.4789e-04,  7.7142e-05, -2.2756e-05],\n",
      "          [-1.3030e-04, -7.4254e-05, -8.9893e-05],\n",
      "          [-4.4038e-05,  7.8915e-06, -3.6205e-05]]],\n",
      "\n",
      "\n",
      "        [[[ 8.9925e-04, -2.1586e-03, -6.9081e-03],\n",
      "          [-2.6162e-03,  5.1902e-03, -8.0884e-04],\n",
      "          [-2.2977e-03,  2.3720e-03,  4.5059e-03]],\n",
      "\n",
      "         [[ 8.4766e-04,  1.0758e-03, -6.0021e-03],\n",
      "          [ 4.0092e-04,  6.5084e-03,  5.8388e-04],\n",
      "          [-7.0620e-04,  2.5902e-04,  4.1883e-03]],\n",
      "\n",
      "         [[-2.5449e-03, -6.0052e-04, -6.4495e-04],\n",
      "          [-1.1669e-03,  2.7958e-03,  5.5653e-03],\n",
      "          [-1.4833e-03, -4.7955e-03, -5.0527e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.2244e-03,  1.3324e-03, -1.3116e-03],\n",
      "          [-3.8324e-03, -9.8929e-04,  3.1771e-03],\n",
      "          [-1.2266e-03, -5.4352e-04, -4.3646e-03]],\n",
      "\n",
      "         [[-5.6261e-04,  1.7280e-05, -1.0742e-03],\n",
      "          [ 3.3420e-03,  3.2062e-03,  1.7149e-03],\n",
      "          [-3.4679e-04, -1.8376e-03, -9.2586e-04]],\n",
      "\n",
      "         [[-1.5084e-03, -8.6456e-04, -2.0234e-03],\n",
      "          [-2.1995e-04,  8.0246e-04, -5.3566e-04],\n",
      "          [ 1.9554e-03, -1.5337e-03, -2.6286e-05]]],\n",
      "\n",
      "\n",
      "        [[[ 9.9447e-05, -1.2018e-03, -2.1770e-03],\n",
      "          [-7.2899e-05, -7.9135e-04,  6.9802e-04],\n",
      "          [-7.7951e-05,  7.1918e-04,  9.4106e-04]],\n",
      "\n",
      "         [[ 1.2749e-04,  6.1054e-04,  1.9467e-03],\n",
      "          [ 1.5241e-04, -4.9492e-04, -1.0189e-03],\n",
      "          [-3.4245e-04,  1.6155e-04, -9.1249e-04]],\n",
      "\n",
      "         [[ 1.6094e-03,  1.0630e-03,  1.7285e-04],\n",
      "          [ 3.7930e-04, -3.4127e-04, -2.6743e-04],\n",
      "          [-1.1491e-03, -1.8586e-03, -9.6931e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.9385e-04, -6.9483e-04, -9.7180e-04],\n",
      "          [-1.9157e-04, -1.3025e-04, -4.0617e-04],\n",
      "          [-1.6029e-04, -2.0357e-04,  1.1048e-04]],\n",
      "\n",
      "         [[ 7.8523e-04,  1.6532e-03, -2.2854e-04],\n",
      "          [-5.9821e-05, -5.5116e-05, -9.2330e-04],\n",
      "          [-1.2605e-03, -6.4565e-04, -1.2997e-03]],\n",
      "\n",
      "         [[ 1.0859e-04,  1.5381e-03,  1.7119e-03],\n",
      "          [ 3.0123e-04,  6.6540e-04, -5.7925e-04],\n",
      "          [-8.7019e-05, -5.1675e-04, -1.0385e-04]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.5905e-03,  1.0201e-02,  1.2123e-03],\n",
      "          [ 4.4357e-03,  8.2618e-03, -3.5572e-03],\n",
      "          [ 3.1160e-03,  2.6746e-03, -1.0503e-02]],\n",
      "\n",
      "         [[-3.4599e-03,  3.8460e-03, -3.5657e-03],\n",
      "          [ 3.2560e-03,  7.8078e-03, -8.2791e-03],\n",
      "          [-4.8782e-03, -1.3199e-03, -5.3870e-03]],\n",
      "\n",
      "         [[ 2.4100e-03, -2.7545e-03, -3.4056e-03],\n",
      "          [ 2.0166e-03, -5.3595e-03, -2.5671e-03],\n",
      "          [-2.2418e-03, -4.3325e-03, -6.5053e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.3220e-03, -5.8720e-04, -4.7461e-03],\n",
      "          [ 4.4753e-03, -1.0421e-03, -6.1991e-03],\n",
      "          [-4.8746e-03, -5.0891e-03,  1.0974e-03]],\n",
      "\n",
      "         [[ 4.5771e-03, -3.4002e-03, -3.8862e-03],\n",
      "          [-1.4895e-03, -6.4079e-03, -2.8218e-04],\n",
      "          [-5.6264e-03, -4.7667e-03,  1.1515e-02]],\n",
      "\n",
      "         [[ 3.4875e-04, -1.5494e-03,  3.9757e-04],\n",
      "          [-6.1528e-04, -4.5411e-04,  7.6064e-03],\n",
      "          [-3.8255e-03, -7.1520e-03, -4.9908e-03]]],\n",
      "\n",
      "\n",
      "        [[[-3.2480e-03, -4.8460e-03, -4.0415e-03],\n",
      "          [-1.9867e-03,  1.0090e-02,  6.0904e-03],\n",
      "          [-5.0698e-03,  4.0331e-03,  9.9800e-03]],\n",
      "\n",
      "         [[-1.7865e-04,  7.1440e-05, -1.1805e-04],\n",
      "          [ 4.6685e-04, -3.1644e-03, -2.5721e-03],\n",
      "          [ 6.2601e-03, -6.2283e-04, -3.0549e-04]],\n",
      "\n",
      "         [[ 2.1715e-03,  2.1092e-03,  5.2626e-05],\n",
      "          [-2.4280e-03, -8.4818e-04,  5.1376e-04],\n",
      "          [-2.3141e-03, -2.5135e-03,  5.5962e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.6187e-04, -9.1036e-04, -1.2463e-03],\n",
      "          [ 4.7596e-03, -2.0558e-05, -6.2147e-04],\n",
      "          [-1.6954e-03, -2.5523e-03, -3.0431e-03]],\n",
      "\n",
      "         [[ 1.9059e-03,  1.9763e-03, -1.0994e-03],\n",
      "          [ 2.5024e-03,  5.2596e-04, -1.9062e-03],\n",
      "          [-2.3961e-03, -9.8968e-04, -6.4078e-05]],\n",
      "\n",
      "         [[ 2.9601e-03,  2.8293e-03,  1.3527e-03],\n",
      "          [-1.0961e-03, -1.6071e-03, -1.3656e-03],\n",
      "          [-2.8181e-03, -1.8249e-03, -1.0015e-05]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4669e-03,  4.3972e-03, -1.9536e-03],\n",
      "          [ 6.6048e-03,  8.0680e-03, -2.1362e-03],\n",
      "          [ 2.9714e-03,  4.4754e-03, -6.8163e-03]],\n",
      "\n",
      "         [[-1.6440e-03,  3.2763e-03, -9.7574e-04],\n",
      "          [ 6.6079e-04,  2.0481e-03, -5.2611e-03],\n",
      "          [ 4.8496e-04,  2.4609e-04, -1.8604e-03]],\n",
      "\n",
      "         [[ 2.1404e-03, -1.2521e-03, -1.5176e-03],\n",
      "          [-1.6175e-04, -1.4334e-03,  1.5286e-03],\n",
      "          [-6.8755e-04, -2.5818e-03, -1.4678e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.5467e-05, -8.0655e-04, -3.3328e-03],\n",
      "          [ 4.2986e-05, -2.6990e-03, -2.2426e-03],\n",
      "          [-9.1743e-04, -1.2422e-03,  4.0153e-04]],\n",
      "\n",
      "         [[ 3.3291e-03, -2.3557e-03, -1.5517e-03],\n",
      "          [ 1.2816e-03, -2.5145e-03,  6.4853e-04],\n",
      "          [-1.7585e-03, -3.0625e-03,  4.4567e-03]],\n",
      "\n",
      "         [[ 4.4528e-04, -9.1755e-04,  5.8493e-04],\n",
      "          [-3.0565e-04, -4.5267e-04,  2.7512e-03],\n",
      "          [-1.6263e-03, -2.5714e-03, -9.4613e-04]]]], device='cuda:0'), 'features.8.bias': tensor([-2.1991e-05, -3.2095e-03, -7.7005e-04,  6.6204e-04, -2.3616e-03,\n",
      "        -7.2807e-04, -1.7358e-05,  1.3269e-03,  1.6538e-03,  5.9365e-04,\n",
      "         1.5765e-03,  1.9113e-03, -5.7765e-03,  1.5101e-03, -2.4291e-03,\n",
      "        -7.2799e-03, -2.4818e-03, -1.3802e-04, -1.8923e-03, -1.5504e-03,\n",
      "        -1.3463e-03,  2.9835e-03, -3.0638e-03, -2.9719e-03, -8.3553e-04,\n",
      "        -1.0127e-02,  3.8692e-03,  2.3614e-04, -1.2726e-04, -1.6941e-04,\n",
      "         7.6808e-05,  3.4338e-05, -4.2545e-03, -1.9688e-04, -9.1738e-04,\n",
      "         3.0669e-04, -5.0431e-04,  2.1834e-03, -1.0218e-03, -9.7433e-04,\n",
      "        -6.4985e-04, -1.4929e-03,  1.1238e-04, -3.0746e-04, -3.9151e-03,\n",
      "         4.4308e-06, -1.2370e-03,  2.8582e-03,  3.8659e-03, -9.4498e-04,\n",
      "        -4.7712e-03,  2.9100e-03, -1.3505e-03, -4.0246e-04,  3.7606e-04,\n",
      "        -2.3290e-04,  1.3953e-03, -5.9530e-04, -3.3933e-04, -4.1242e-04,\n",
      "        -3.0819e-03,  7.8458e-04, -7.7241e-05, -4.8699e-04,  3.3302e-03,\n",
      "        -1.5846e-03,  9.3449e-04, -2.1649e-03,  6.6662e-06, -4.9657e-03,\n",
      "        -7.2568e-04, -5.3105e-03, -1.5642e-03, -8.7461e-04, -1.4924e-03,\n",
      "        -1.6493e-03, -1.9229e-05,  3.3113e-03, -2.2184e-04, -2.3387e-03,\n",
      "        -7.2111e-04, -4.5707e-03, -1.0806e-03, -6.9597e-04,  2.3274e-05,\n",
      "        -6.1899e-03, -1.4632e-03,  1.7375e-03, -5.9876e-03, -4.5503e-03,\n",
      "         1.5805e-03, -3.9408e-05, -3.4572e-03, -7.5007e-03, -8.9897e-04,\n",
      "        -3.4528e-03, -5.9735e-03,  1.5170e-03, -5.9418e-03, -8.2136e-04,\n",
      "        -3.7027e-04, -1.1223e-03,  2.2125e-03,  7.3860e-04, -5.7604e-05,\n",
      "        -1.1070e-04, -1.2217e-02, -3.1240e-03, -3.4287e-04, -5.7968e-03,\n",
      "        -5.3584e-03, -1.3131e-03, -1.3784e-03, -2.1114e-03, -3.1938e-03,\n",
      "        -2.6118e-03, -2.1175e-03, -8.1467e-04, -8.3243e-04, -2.0247e-03,\n",
      "        -2.0301e-03,  9.7732e-06,  3.8163e-03, -1.1696e-04,  9.7966e-09,\n",
      "         1.1191e-04, -3.3135e-03,  2.6850e-03, -1.3524e-04,  8.4333e-04,\n",
      "        -2.3825e-03,  7.3113e-04, -4.9274e-03, -3.2166e-03, -4.0189e-03,\n",
      "         7.3700e-04, -3.0412e-04, -5.0173e-04, -5.7767e-03,  6.2912e-04,\n",
      "        -1.5796e-04, -1.1622e-03, -4.3193e-04, -1.6333e-03,  2.5395e-04,\n",
      "        -6.8739e-03, -3.9317e-03, -1.9633e-03, -4.4906e-03, -4.8259e-03,\n",
      "        -1.2661e-03, -2.8121e-03, -4.9763e-03, -3.1935e-03, -2.5134e-03,\n",
      "         3.7340e-04,  4.6199e-04, -1.6637e-03, -5.9764e-03, -6.6725e-04,\n",
      "        -5.2056e-03, -1.0855e-03, -1.5345e-03, -1.5773e-03, -3.6244e-03,\n",
      "         1.1567e-03, -3.6605e-03, -3.1587e-03, -2.2704e-03, -8.3521e-04,\n",
      "        -1.3811e-03, -3.5514e-03, -5.7215e-03,  1.1890e-04, -2.4331e-04,\n",
      "        -1.2071e-03, -1.2526e-04, -8.8300e-04, -4.9452e-04, -8.7226e-04,\n",
      "        -9.6208e-04, -4.1634e-04, -1.4427e-03, -2.7077e-03, -2.4388e-03,\n",
      "        -3.2399e-04, -6.6381e-04, -7.7347e-04,  2.4127e-04, -9.4192e-10,\n",
      "         1.1196e-03, -1.0054e-05, -2.0849e-03,  8.5657e-04, -2.0043e-03,\n",
      "         2.6634e-04, -7.6884e-05,  9.6992e-04,  1.4573e-04,  5.5859e-11,\n",
      "         7.7165e-03,  3.0881e-03, -5.6631e-04, -1.2719e-03, -2.2999e-03,\n",
      "        -1.2857e-03, -6.4692e-03,  1.4868e-03, -6.3466e-04,  3.2756e-03,\n",
      "        -4.1701e-03, -1.2424e-03, -1.0712e-03,  3.8488e-04, -1.3474e-03,\n",
      "        -1.8569e-04, -3.4120e-03,  7.2623e-04,  2.5304e-04, -8.7083e-05,\n",
      "         1.0734e-04, -5.2966e-04, -4.0324e-03,  1.8805e-03, -1.0389e-02,\n",
      "        -2.8624e-03,  9.0737e-08,  8.0657e-04, -2.7666e-03, -8.3517e-05,\n",
      "        -3.9753e-04,  1.3539e-03,  5.3734e-03, -3.7248e-04, -7.7035e-03,\n",
      "        -4.3212e-03,  1.0584e-04, -4.8722e-04,  6.8912e-09, -3.4054e-05,\n",
      "         9.2327e-05,  2.3259e-07,  1.8121e-03, -6.7449e-04,  7.1328e-04,\n",
      "         1.5463e-07, -1.8483e-03,  3.7359e-03,  1.7780e-03, -3.2316e-05,\n",
      "        -1.3728e-03,  5.9373e-05,  8.4870e-07,  1.5442e-03, -1.0620e-03,\n",
      "         2.2215e-03], device='cuda:0'), 'classifier.0.weight': tensor([[ 1.1027e-06,  2.8724e-07, -5.7205e-06,  ..., -3.2494e-06,\n",
      "         -1.1515e-04,  3.4638e-06],\n",
      "        [ 4.4518e-06, -1.7374e-05, -1.9582e-05,  ..., -6.0580e-05,\n",
      "          9.7139e-04,  2.5465e-04],\n",
      "        [ 4.8661e-05, -3.6096e-05, -1.4774e-05,  ...,  1.6710e-03,\n",
      "         -1.4051e-03,  3.3918e-04],\n",
      "        ...,\n",
      "        [ 3.3408e-05,  5.6609e-05, -2.0545e-07,  ...,  1.3365e-03,\n",
      "         -2.2549e-03, -1.0474e-03],\n",
      "        [ 8.6663e-06, -1.3502e-05, -3.7545e-05,  ..., -5.8293e-04,\n",
      "         -4.4387e-04,  2.4180e-04],\n",
      "        [-5.1061e-06, -1.9987e-05, -1.7833e-05,  ..., -5.9752e-04,\n",
      "         -6.5843e-04,  5.6309e-04]], device='cuda:0'), 'classifier.0.bias': tensor([-4.0166e-05, -7.2881e-04,  1.9562e-03,  ...,  5.2611e-04,\n",
      "        -9.3120e-05,  2.4564e-04], device='cuda:0'), 'classifier.2.weight': tensor([[-4.5710e-04, -6.8171e-03,  5.1625e-02,  ...,  6.6180e-02,\n",
      "         -7.3588e-04, -4.6042e-03],\n",
      "        [-7.1344e-04, -6.8326e-03,  4.3315e-04,  ..., -1.2496e-02,\n",
      "         -2.7090e-03, -6.2575e-03],\n",
      "        [-8.1483e-04, -3.4599e-03, -2.6604e-02,  ..., -2.3587e-02,\n",
      "         -2.2472e-03, -1.4343e-03],\n",
      "        ...,\n",
      "        [-4.9644e-04, -7.7395e-03,  5.8729e-03,  ..., -9.4477e-03,\n",
      "          1.5698e-03, -7.8267e-03],\n",
      "        [ 1.1229e-03,  9.1069e-05,  2.5755e-02,  ..., -1.9607e-02,\n",
      "         -4.2326e-03, -3.3108e-03],\n",
      "        [-7.3861e-04,  2.6389e-02, -1.6533e-02,  ..., -5.5501e-03,\n",
      "         -2.1577e-03, -6.3683e-04]], device='cuda:0'), 'classifier.2.bias': tensor([-0.0016,  0.0568, -0.0146,  0.0128, -0.0159, -0.0105, -0.0324, -0.0014,\n",
      "         0.0216, -0.0149], device='cuda:0')}\n"
     ]
    }
   ],
   "source": [
    "original_weights = {}\n",
    "\n",
    "for name , param in model.named_parameters():\n",
    "\n",
    "    original_weights[name] = param.clone().detach()\n",
    "\n",
    "print(original_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# now test this model on each numbers in mnist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|| 1000/1000 [00:01<00:00, 574.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.986\n",
      "wrong counts for the digit 0: 7\n",
      "wrong counts for the digit 1: 10\n",
      "wrong counts for the digit 2: 7\n",
      "wrong counts for the digit 3: 5\n",
      "wrong counts for the digit 4: 31\n",
      "wrong counts for the digit 5: 11\n",
      "wrong counts for the digit 6: 14\n",
      "wrong counts for the digit 7: 30\n",
      "wrong counts for the digit 8: 13\n",
      "wrong counts for the digit 9: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    wrong_counts = [0 for i in range(10)]\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for data in tqdm(test_loader , desc='Testing'):\n",
    "\n",
    "                x,y = data\n",
    "\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "                output = model(x)\n",
    "\n",
    "                for idx , i in enumerate(output):\n",
    "\n",
    "                    if torch.argmax(i) == y[idx]:\n",
    "                        correct += 1\n",
    "                    else:\n",
    "                        wrong_counts[y[idx]] +=1\n",
    "                    total+=1\n",
    "    print(f'Accuracy: {round(correct/total, 3)}')\n",
    "    for i in range(len(wrong_counts)):\n",
    "        print(f'wrong counts for the digit {i}: {wrong_counts[i]}')\n",
    "\n",
    "test()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Total number of parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer features.0: W: torch.Size([64, 1, 3, 3]) + B: torch.Size([64])\n",
      "Parameters: 640\n",
      "Layer features.3: W: torch.Size([128, 64, 3, 3]) + B: torch.Size([128])\n",
      "Parameters: 73856\n",
      "Layer features.6: W: torch.Size([256, 128, 3, 3]) + B: torch.Size([256])\n",
      "Parameters: 295168\n",
      "Layer features.8: W: torch.Size([256, 256, 3, 3]) + B: torch.Size([256])\n",
      "Parameters: 590080\n",
      "Layer classifier.0: W: torch.Size([1024, 2304]) + B: torch.Size([1024])\n",
      "Parameters: 2360320\n",
      "Layer classifier.2: W: torch.Size([10, 1024]) + B: torch.Size([10])\n",
      "Parameters: 10250\n",
      "Total number of parameters: 3,330,314\n"
     ]
    }
   ],
   "source": [
    "total_params = 0\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, (nn.Conv2d, nn.Linear)):\n",
    "        weights_params = module.weight.nelement()\n",
    "        bias_params = module.bias.nelement() if module.bias is not None else 0\n",
    "        total_params += weights_params + bias_params\n",
    "        print(f'Layer {name}: W: {module.weight.shape} + B: {module.bias.shape if module.bias is not None else \"No bias\"}')\n",
    "        print(f'Parameters: {weights_params + bias_params}')\n",
    "\n",
    "print(f'Total number of parameters: {total_params:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchsummary\n",
      "  Downloading torchsummary-1.5.1-py3-none-any.whl.metadata (296 bytes)\n",
      "Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\n",
      "Installing collected packages: torchsummary\n",
      "Successfully installed torchsummary-1.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 28, 28]             640\n",
      "              ReLU-2           [-1, 64, 28, 28]               0\n",
      "         MaxPool2d-3           [-1, 64, 14, 14]               0\n",
      "            Conv2d-4          [-1, 128, 14, 14]          73,856\n",
      "              ReLU-5          [-1, 128, 14, 14]               0\n",
      "         MaxPool2d-6            [-1, 128, 7, 7]               0\n",
      "            Conv2d-7            [-1, 256, 7, 7]         295,168\n",
      "              ReLU-8            [-1, 256, 7, 7]               0\n",
      "            Conv2d-9            [-1, 256, 7, 7]         590,080\n",
      "             ReLU-10            [-1, 256, 7, 7]               0\n",
      "        MaxPool2d-11            [-1, 256, 3, 3]               0\n",
      "           Linear-12                 [-1, 1024]       2,360,320\n",
      "             ReLU-13                 [-1, 1024]               0\n",
      "           Linear-14                   [-1, 10]          10,250\n",
      "================================================================\n",
      "Total params: 3,330,314\n",
      "Trainable params: 3,330,314\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 1.71\n",
      "Params size (MB): 12.70\n",
      "Estimated Total Size (MB): 14.42\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(model, (1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoRAParametrization(nn.Module):\n",
    "    def __init__(self, features_in, features_out, rank=1, alpha=1, device='cpu'):\n",
    "        super().__init__()\n",
    "        # Section 4.1 of the paper: \n",
    "        #   We use a random Gaussian initialization for A and zero for B, so W = BA is zero at the beginning of training\n",
    "        self.lora_A = nn.Parameter(torch.zeros((rank,features_out)).to(device))\n",
    "        self.lora_B = nn.Parameter(torch.zeros((features_in, rank)).to(device))\n",
    "        nn.init.normal_(self.lora_A, mean=0, std=1)\n",
    "        \n",
    "        # Section 4.1 of the paper: \n",
    "        #   We then scale Wx by /r , where  is a constant in r. \n",
    "        #   When optimizing with Adam, tuning  is roughly the same as tuning the learning rate if we scale the initialization appropriately. \n",
    "        #   As a result, we simply set  to the first r we try and do not tune it. \n",
    "        #   This scaling helps to reduce the need to retune hyperparameters when we vary r.\n",
    "        self.scale = alpha / rank\n",
    "        self.enabled = True\n",
    "\n",
    "    def forward(self, original_weights):\n",
    "        if self.enabled:\n",
    "            # Return W + (B*A)*scale\n",
    "            return original_weights + torch.matmul(self.lora_B, self.lora_A).view(original_weights.shape) * self.scale\n",
    "        else:\n",
    "            return original_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.utils.parametrize as parametrize\n",
    "\n",
    "def conv_layer_parameterization(layer, device, rank=1, lora_alpha=1):\n",
    "    features_in = layer.weight.shape[1] * layer.weight.shape[2] * layer.weight.shape[3]\n",
    "    features_out = layer.weight.shape[0]\n",
    "    return LoRAParametrization(\n",
    "        features_in, features_out, rank=rank, alpha=lora_alpha, device=device\n",
    "    )\n",
    "\n",
    "def linear_layer_parameterization(layer, device, rank=1, lora_alpha=1):\n",
    "    features_in, features_out = layer.weight.shape\n",
    "    return LoRAParametrization(\n",
    "        features_in, features_out, rank=rank, alpha=lora_alpha, device=device\n",
    "    )\n",
    "\n",
    "def add_lora_to_model(model, device, rank=1, lora_alpha=1):\n",
    "    # Add LoRA to convolutional layers\n",
    "    for i, layer in enumerate(model.features):\n",
    "        if isinstance(layer, nn.Conv2d):\n",
    "            parametrize.register_parametrization(\n",
    "                layer, \"weight\", conv_layer_parameterization(layer, device, rank, lora_alpha)\n",
    "            )\n",
    "\n",
    "    # Add LoRA to linear layers\n",
    "    for i, layer in enumerate(model.classifier):\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            parametrize.register_parametrization(\n",
    "                layer, \"weight\", linear_layer_parameterization(layer, device, rank, lora_alpha)\n",
    "            )\n",
    "\n",
    "def enable_disable_lora(model, enabled=True):\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, (nn.Conv2d, nn.Linear)) and hasattr(module, 'parametrizations'):\n",
    "            module.parametrizations[\"weight\"][0].enabled = enabled\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    total_params_original = 0\n",
    "    total_params_lora = 0\n",
    "    \n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, (nn.Conv2d, nn.Linear)):\n",
    "            weights_params = module.weight.nelement()\n",
    "            bias_params = module.bias.nelement() if module.bias is not None else 0\n",
    "            total_params_original += weights_params + bias_params\n",
    "            \n",
    "            if hasattr(module, 'parametrizations'):\n",
    "                lora_params = module.parametrizations[\"weight\"][0].lora_A.nelement() + \\\n",
    "                              module.parametrizations[\"weight\"][0].lora_B.nelement()\n",
    "                total_params_lora += lora_params\n",
    "                \n",
    "                print(f'Layer {name}:')\n",
    "                print(f'  W: {module.weight.shape}')\n",
    "                print(f'  B: {module.bias.shape if module.bias is not None else \"No bias\"}')\n",
    "                print(f'  Lora_A: {module.parametrizations[\"weight\"][0].lora_A.shape}')\n",
    "                print(f'  Lora_B: {module.parametrizations[\"weight\"][0].lora_B.shape}')\n",
    "                print(f'  Parameters: {weights_params + bias_params + lora_params}')\n",
    "            else:\n",
    "                print(f'Layer {name}:')\n",
    "                print(f'  W: {module.weight.shape}')\n",
    "                print(f'  B: {module.bias.shape if module.bias is not None else \"No bias\"}')\n",
    "                print(f'  Parameters: {weights_params + bias_params}')\n",
    "    \n",
    "    print(f'\\nTotal number of parameters (original): {total_params_original:,}')\n",
    "    print(f'Total number of parameters (original + LoRA): {total_params_original + total_params_lora:,}')\n",
    "    print(f'Parameters introduced by LoRA: {total_params_lora:,}')\n",
    "    parameters_increment = (total_params_lora / total_params_original) * 100\n",
    "    print(f'Parameters increment: {parameters_increment:.3f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters before adding LoRA:\n",
      "Layer features.0:\n",
      "  W: torch.Size([64, 1, 3, 3])\n",
      "  B: torch.Size([64])\n",
      "  Parameters: 640\n",
      "Layer features.3:\n",
      "  W: torch.Size([128, 64, 3, 3])\n",
      "  B: torch.Size([128])\n",
      "  Parameters: 73856\n",
      "Layer features.6:\n",
      "  W: torch.Size([256, 128, 3, 3])\n",
      "  B: torch.Size([256])\n",
      "  Parameters: 295168\n",
      "Layer features.8:\n",
      "  W: torch.Size([256, 256, 3, 3])\n",
      "  B: torch.Size([256])\n",
      "  Parameters: 590080\n",
      "Layer classifier.0:\n",
      "  W: torch.Size([1024, 2304])\n",
      "  B: torch.Size([1024])\n",
      "  Parameters: 2360320\n",
      "Layer classifier.2:\n",
      "  W: torch.Size([10, 1024])\n",
      "  B: torch.Size([10])\n",
      "  Parameters: 10250\n",
      "\n",
      "Total number of parameters (original): 3,330,314\n",
      "Total number of parameters (original + LoRA): 3,330,314\n",
      "Parameters introduced by LoRA: 0\n",
      "Parameters increment: 0.000%\n",
      "\n",
      "Parameters after adding LoRA:\n",
      "Layer features.0:\n",
      "  W: torch.Size([64, 1, 3, 3])\n",
      "  B: torch.Size([64])\n",
      "  Lora_A: torch.Size([4, 64])\n",
      "  Lora_B: torch.Size([9, 4])\n",
      "  Parameters: 932\n",
      "Layer features.3:\n",
      "  W: torch.Size([128, 64, 3, 3])\n",
      "  B: torch.Size([128])\n",
      "  Lora_A: torch.Size([4, 128])\n",
      "  Lora_B: torch.Size([576, 4])\n",
      "  Parameters: 76672\n",
      "Layer features.6:\n",
      "  W: torch.Size([256, 128, 3, 3])\n",
      "  B: torch.Size([256])\n",
      "  Lora_A: torch.Size([4, 256])\n",
      "  Lora_B: torch.Size([1152, 4])\n",
      "  Parameters: 300800\n",
      "Layer features.8:\n",
      "  W: torch.Size([256, 256, 3, 3])\n",
      "  B: torch.Size([256])\n",
      "  Lora_A: torch.Size([4, 256])\n",
      "  Lora_B: torch.Size([2304, 4])\n",
      "  Parameters: 600320\n",
      "Layer classifier.0:\n",
      "  W: torch.Size([1024, 2304])\n",
      "  B: torch.Size([1024])\n",
      "  Lora_A: torch.Size([4, 2304])\n",
      "  Lora_B: torch.Size([1024, 4])\n",
      "  Parameters: 2373632\n",
      "Layer classifier.2:\n",
      "  W: torch.Size([10, 1024])\n",
      "  B: torch.Size([10])\n",
      "  Lora_A: torch.Size([4, 1024])\n",
      "  Lora_B: torch.Size([10, 4])\n",
      "  Parameters: 14386\n",
      "\n",
      "Total number of parameters (original): 3,330,314\n",
      "Total number of parameters (original + LoRA): 3,366,742\n",
      "Parameters introduced by LoRA: 36,428\n",
      "Parameters increment: 1.094%\n"
     ]
    }
   ],
   "source": [
    "print(\"Parameters before adding LoRA:\")\n",
    "count_parameters(model)\n",
    "\n",
    "# Add LoRA to the model\n",
    "add_lora_to_model(model, device, rank=4, lora_alpha=1)\n",
    "\n",
    "# Count parameters after adding LoRA\n",
    "print(\"\\nParameters after adding LoRA:\")\n",
    "count_parameters(model)\n",
    "\n",
    "# Example of enabling/disabling LoRA\n",
    "enable_disable_lora(model, enabled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now lets finetune for 9  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader , model , epochs=5 , total_iterations_limit = None):\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = 0.005, momentum = 0.9)  \n",
    "\n",
    "\n",
    "        # Train the model\n",
    "        total_step = len(train_loader)\n",
    "\n",
    "        total_step = len(train_loader)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            for i, (images, labels) in enumerate(train_loader):  \n",
    "                # Move tensors to the configured device\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                # Backward and optimize\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                        .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "                    \n",
    "            # Validation\n",
    "            with torch.no_grad():\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                for images, labels in test_loader:\n",
    "                    images = images.to(device)\n",
    "                    labels = labels.to(device)\n",
    "                    outputs = model(images)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "                    del images, labels, outputs\n",
    "            \n",
    "                print('Accuracy of the network on the {} validation images: {} %'.format(5000, 100 * correct / total)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing non-LoRA parameter features.0.bias\n",
      "Freezing non-LoRA parameter features.0.parametrizations.weight.original\n",
      "Freezing non-LoRA parameter features.3.bias\n",
      "Freezing non-LoRA parameter features.3.parametrizations.weight.original\n",
      "Freezing non-LoRA parameter features.6.bias\n",
      "Freezing non-LoRA parameter features.6.parametrizations.weight.original\n",
      "Freezing non-LoRA parameter features.8.bias\n",
      "Freezing non-LoRA parameter features.8.parametrizations.weight.original\n",
      "Freezing non-LoRA parameter classifier.0.bias\n",
      "Freezing non-LoRA parameter classifier.0.parametrizations.weight.original\n",
      "Freezing non-LoRA parameter classifier.2.bias\n",
      "Freezing non-LoRA parameter classifier.2.parametrizations.weight.original\n",
      "Epoch [1/10], Step [595/595], Loss: 0.0000\n",
      "Accuracy of the network on the 5000 validation images: 77.5 %\n",
      "Epoch [2/10], Step [595/595], Loss: 0.0000\n",
      "Accuracy of the network on the 5000 validation images: 84.91 %\n",
      "Epoch [3/10], Step [595/595], Loss: 0.0000\n",
      "Accuracy of the network on the 5000 validation images: 88.28 %\n",
      "Epoch [4/10], Step [595/595], Loss: 0.0000\n",
      "Accuracy of the network on the 5000 validation images: 87.82 %\n",
      "Epoch [5/10], Step [595/595], Loss: 0.0000\n",
      "Accuracy of the network on the 5000 validation images: 89.32 %\n",
      "Epoch [6/10], Step [595/595], Loss: 0.0001\n",
      "Accuracy of the network on the 5000 validation images: 91.56 %\n",
      "Epoch [7/10], Step [595/595], Loss: 0.0000\n",
      "Accuracy of the network on the 5000 validation images: 93.1 %\n",
      "Epoch [8/10], Step [595/595], Loss: 0.0042\n",
      "Accuracy of the network on the 5000 validation images: 93.81 %\n",
      "Epoch [9/10], Step [595/595], Loss: 0.0001\n",
      "Accuracy of the network on the 5000 validation images: 93.45 %\n",
      "Epoch [10/10], Step [595/595], Loss: 0.0000\n",
      "Accuracy of the network on the 5000 validation images: 94.86 %\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if 'lora' not in name:\n",
    "        print(f'Freezing non-LoRA parameter {name}')\n",
    "        param.requires_grad = False\n",
    "\n",
    "# Load the MNIST dataset again, by keeping only the digit 9\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "exclude_indices = mnist_trainset.targets == 9\n",
    "mnist_trainset.data = mnist_trainset.data[exclude_indices]\n",
    "mnist_trainset.targets = mnist_trainset.targets[exclude_indices]\n",
    "# Create a dataloader for the training\n",
    "train_loader = torch.utils.data.DataLoader(mnist_trainset, batch_size=10, shuffle=True)\n",
    "\n",
    "# Train the network with LoRA only on the digit 9 and only for 100 batches (hoping that it would improve the performance on the digit 9)\n",
    "train(train_loader, model, epochs=1, total_iterations_limit=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|| 1000/1000 [00:02<00:00, 482.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.949\n",
      "wrong counts for the digit 0: 37\n",
      "wrong counts for the digit 1: 14\n",
      "wrong counts for the digit 2: 10\n",
      "wrong counts for the digit 3: 16\n",
      "wrong counts for the digit 4: 148\n",
      "wrong counts for the digit 5: 55\n",
      "wrong counts for the digit 6: 18\n",
      "wrong counts for the digit 7: 158\n",
      "wrong counts for the digit 8: 58\n",
      "wrong counts for the digit 9: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "enable_disable_lora(model,enabled=True)\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|| 1000/1000 [00:01<00:00, 561.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.986\n",
      "wrong counts for the digit 0: 7\n",
      "wrong counts for the digit 1: 10\n",
      "wrong counts for the digit 2: 7\n",
      "wrong counts for the digit 3: 5\n",
      "wrong counts for the digit 4: 31\n",
      "wrong counts for the digit 5: 11\n",
      "wrong counts for the digit 6: 14\n",
      "wrong counts for the digit 7: 30\n",
      "wrong counts for the digit 8: 13\n",
      "wrong counts for the digit 9: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "enable_disable_lora(model,enabled=False)\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI702",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
